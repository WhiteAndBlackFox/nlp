{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part-of-Speech разметка, NER, извлечение отношений.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsjPvzhuJtFEuSFXpUsZsD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteAndBlackFox/nlp/blob/POS/Part_of_Speech_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%82%D0%BA%D0%B0%2C_NER%2C_%D0%B8%D0%B7%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BE%D1%82%D0%BD%D0%BE%D1%88%D0%B5%D0%BD%D0%B8%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-of-Speech разметка, NER, извлечение отношений"
      ],
      "metadata": {
        "id": "N7UHGCz12E7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подключение библиотек"
      ],
      "metadata": {
        "id": "5TC56NUA2aEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ставим все недостоющие библиотеки\n",
        "!pip install pyconll\n",
        "!pip install corus\n",
        "!pip install -U spacy\n",
        "!python -m spacy download ru_core_news_sm  \n",
        "!pip install razdel\n",
        "\n",
        "!pip install -U tensorflow tensorflow-gpu\n",
        "!pip install numpy scipy librosa unidecode inflect librosa transformers\n"
      ],
      "metadata": {
        "id": "gjNBnwZD20RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Скачиваем данные для анализа\n",
        "!mkdir datasets\n",
        "!wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
        "\n",
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
        "!unzip collection5.zip\n",
        "!rm collection5.zip"
      ],
      "metadata": {
        "id": "e9Z-Tp373BGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyconll\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import en_core_web_sm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger, NgramTagger\n",
        "for val in ['punkt', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words']:\n",
        "  nltk.download(val)\n",
        "\n",
        "from corus import load_ne5\n",
        "from razdel import tokenize\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.lang.ru.examples import sentences \n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyKSOgT-2ZW5",
        "outputId": "4aca5b68-190e-4291-b069-f1f51fcbe7cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дополнительные функции"
      ],
      "metadata": {
        "id": "maNMm4SJ6n6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_tagger(train_data, test_data, tagger_cl, backoff=None):\n",
        "  \"\"\"\n",
        "    Функция для оценки UnigramTagger, BigramTagger, TrigramTagger\n",
        "  \"\"\"\n",
        "  tagger = tagger_cl(train_data, backoff=backoff)\n",
        "  return tagger.evaluate(test_data)\n",
        "\n",
        "def backoff_tagger(train_data, tagger_cl, backoff=None):\n",
        "  \"\"\"\n",
        "    Функция для создании 3-х этапного таггера\n",
        "  \"\"\"\n",
        "  for cls in tagger_cl:\n",
        "      backoff = cls(train_data, backoff=backoff)\n",
        "  return backoff"
      ],
      "metadata": {
        "id": "HCbVClis6nly"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1. Напишем теггер на данных с русским языком"
      ],
      "metadata": {
        "id": "CgiIqMct2YPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Проверим UnigramTagger, BigramTagger, TrigramTagger и их комбмнации"
      ],
      "metadata": {
        "id": "E1XyeTZX3p1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iZFrU44J165K"
      },
      "outputs": [],
      "source": [
        "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')\n",
        "result = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "test_sent = []\n",
        "\n",
        "for sent in full_train[:]:\n",
        "    train_data.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "for sent in full_test[:]:\n",
        "    test_data.append([(token.form, token.upos) for token in sent])\n",
        "    test_sent.append([(token.form, token.upos) for token in sent])"
      ],
      "metadata": {
        "id": "hW2ab1Om39HS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Для каждого таггера считаем отдельно сначало\n",
        "for tagger_cl in [UnigramTagger, BigramTagger, TrigramTagger]:\n",
        "    result[tagger_cl.__name__] = {\n",
        "        'accuracy': eval_tagger(train_data, test_data, tagger_cl)\n",
        "    }"
      ],
      "metadata": {
        "id": "5WbyVUms4GH7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Теперь в сочитании таггеры\n",
        "for tagger_cl in [UnigramTagger, BigramTagger, TrigramTagger]:\n",
        "    for backoff in [UnigramTagger, BigramTagger, TrigramTagger]:\n",
        "        if tagger_cl.__name__ == backoff.__name__:\n",
        "            continue\n",
        "        back_name = f'{tagger_cl.__name__}/{backoff.__name__}'\n",
        "        backoff_cl = backoff(train_data)\n",
        "        result[back_name] = {'accuracy': eval_tagger(\n",
        "            train_data, test_data, tagger_cl, backoff=backoff_cl)\n",
        "        }"
      ],
      "metadata": {
        "id": "WoH0WhPh6YJ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-х этапный таггер - TrigramTagger/BigramTagger/UnigramTagger\n",
        "tag = backoff_tagger(train_data,\n",
        "                     [BigramTagger, TrigramTagger],\n",
        "                     backoff=UnigramTagger(train_data))\n",
        "result['TrigramTagger/BigramTagger/UnigramTagger'] = {\n",
        "    'accuracy': tag.evaluate(test_data)\n",
        "}"
      ],
      "metadata": {
        "id": "cL-od726AHbS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Написшем свой теггер, попробуя разные векторайзеры, добавив знание не только букв но и слов"
      ],
      "metadata": {
        "id": "ZaZbqsrHBKcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in train_data[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append(str(tok[0]))\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "\n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in test_data[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append(str(tok[0]))\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "metadata": {
        "id": "BaKGLwp5BIzS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "test_enc_labels = le.transform(test_label)"
      ],
      "metadata": {
        "id": "Jm_XlFAhBbpq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_vect = {\n",
        "    'HashingVectorizer_char': HashingVectorizer(ngram_range=(1, 5), analyzer='char'),\n",
        "    'HashingVectorizer_100': HashingVectorizer(n_features=100),\n",
        "    'CountVectorizer_char': CountVectorizer(ngram_range=(1, 5), analyzer='char'),\n",
        "    'CountVectorizer': CountVectorizer(),\n",
        "    'TfidfVectorizer_char': TfidfVectorizer(ngram_range=(1, 5), analyzer='char'),\n",
        "    'TfidfVectorizer': TfidfVectorizer()\n",
        "}\n",
        "\n",
        "for name_vect, vect in dict_vect.items():\n",
        "  x_train = vect.fit_transform(train_tok)\n",
        "  x_test = vect.transform(test_tok)\n",
        "  model = LogisticRegression(random_state=15)\n",
        "  model.fit(x_train, train_enc_labels)\n",
        "  pred = model.predict(x_test)\n",
        "  result[name_vect] = { 'accuracy': accuracy_score(test_enc_labels, pred) }\n"
      ],
      "metadata": {
        "id": "62NACfwPBfNa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(result).transpose().sort_values(by='accuracy', ascending=False)\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "uFJrVhB4DrZx",
        "outputId": "e6c5ff4d-52e2-4d38-b4d5-135216e014e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          accuracy\n",
              "CountVectorizer_char                      0.942034\n",
              "TfidfVectorizer_char                      0.931766\n",
              "HashingVectorizer_char                    0.924513\n",
              "BigramTagger/UnigramTagger                0.829279\n",
              "TrigramTagger/BigramTagger/UnigramTagger  0.829143\n",
              "TrigramTagger/UnigramTagger               0.828550\n",
              "UnigramTagger                             0.823732\n",
              "CountVectorizer                           0.696159\n",
              "TfidfVectorizer                           0.696152\n",
              "UnigramTagger/BigramTagger                0.617618\n",
              "BigramTagger                              0.609389\n",
              "TrigramTagger/BigramTagger                0.609180\n",
              "HashingVectorizer_100                     0.280435\n",
              "UnigramTagger/TrigramTagger               0.267986\n",
              "BigramTagger/TrigramTagger                0.211993\n",
              "TrigramTagger                             0.177863"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbc79737-fb54-4009-b7e8-082ef517928a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CountVectorizer_char</th>\n",
              "      <td>0.942034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TfidfVectorizer_char</th>\n",
              "      <td>0.931766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HashingVectorizer_char</th>\n",
              "      <td>0.924513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BigramTagger/UnigramTagger</th>\n",
              "      <td>0.829279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TrigramTagger/BigramTagger/UnigramTagger</th>\n",
              "      <td>0.829143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TrigramTagger/UnigramTagger</th>\n",
              "      <td>0.828550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UnigramTagger</th>\n",
              "      <td>0.823732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CountVectorizer</th>\n",
              "      <td>0.696159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TfidfVectorizer</th>\n",
              "      <td>0.696152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UnigramTagger/BigramTagger</th>\n",
              "      <td>0.617618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BigramTagger</th>\n",
              "      <td>0.609389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TrigramTagger/BigramTagger</th>\n",
              "      <td>0.609180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HashingVectorizer_100</th>\n",
              "      <td>0.280435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UnigramTagger/TrigramTagger</th>\n",
              "      <td>0.267986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BigramTagger/TrigramTagger</th>\n",
              "      <td>0.211993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TrigramTagger</th>\n",
              "      <td>0.177863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbc79737-fb54-4009-b7e8-082ef517928a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbc79737-fb54-4009-b7e8-082ef517928a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbc79737-fb54-4009-b7e8-082ef517928a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Сравним все реализованные методы и сделаем выводы\n",
        "\n",
        "**Вывод**\n",
        "\n",
        "Судя по результатам:\n",
        "1. Для одиночных теггеров лучше использовать *UnigramTagger* у него точность 0.823732\n",
        "2. Для множественного теггера лучше использовать *CountVectorizer_char* у него показатель 0.939469"
      ],
      "metadata": {
        "id": "bZrtrukiFACx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2. Проверить насколько хорошо работает NER"
      ],
      "metadata": {
        "id": "hlE74impFsgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Проверим NER из nltk/spacy\n"
      ],
      "metadata": {
        "id": "YXwA6yNKF5c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"На площади Южного мола 15 ресторанов представили гостям лучшие блюда из своего меню. Более 10 участников-производителей собственной продукции и фермеров предложили сладости, мед, орехи, грибы, напитки, колбасы, сыр, натуральное мороженое. В рамках концертной программы выступили шоу барабанщиков, музыкальные группы, ди-джеи. Летний тур фестиваля будет проходить в течение всего курортного сезона на самых живописных площадках города. За этот период на нем выступят более 90 исполнителей, ди-джеев и музыкальных коллективов. Мероприятия пройдут на площади Южного мола у сочинского Морского порта, на площади курорта «Роза Хутор» в горном кластере Сочи, на набережной ТРЦ «Мандарин» в Адлерском районе. Гостей ждет насыщенная концертно-развлекательная программа и кулинарные мастер-классы. Также в дни фестиваля сочинцы и гости курорта смогут посетить фермерские дворики, интерактивные локации, спортивные и игровые зоны, занятия утренней йогой. Вход на мероприятия свободный.\""
      ],
      "metadata": {
        "id": "f79xK_fZR4qB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title nltk\n",
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(txt))) if hasattr(chunk, 'label') }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sydEakYSW9F",
        "outputId": "e7fae560-b102-488e-e0bf-1c076e92c19f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Южного', 'PERSON')}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title spacy\n",
        "nlp = spacy.load('ru_core_news_sm')\n",
        "docs = nlp(txt)\n",
        "displacy.render(docs, jupyter=True, style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "XsNYtoUISZIC",
        "outputId": "94e74d84-7971-4e3d-88c1-c37802c49090"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">На площади \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Южного мола\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " 15 ресторанов представили гостям лучшие блюда из своего меню. Более 10 участников-производителей собственной продукции и фермеров предложили сладости, мед, орехи, грибы, напитки, колбасы, сыр, натуральное мороженое. В рамках концертной программы выступили шоу барабанщиков, музыкальные группы, ди-джеи. Летний тур фестиваля будет проходить в течение всего курортного сезона на самых живописных площадках города. За этот период на нем выступят более 90 исполнителей, ди-джеев и музыкальных коллективов. Мероприятия пройдут на площади \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Южного мола\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " у сочинского \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Морского порта\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", на площади курорта «Роза Хутор» в горном кластере \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Сочи\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", на набережной \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ТРЦ «Мандарин»\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Адлерском районе\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". Гостей ждет насыщенная концертно-развлекательная программа и кулинарные мастер-классы. Также в дни фестиваля сочинцы и гости курорта смогут посетить фермерские дворики, интерактивные локации, спортивные и игровые зоны, занятия утренней йогой. Вход на мероприятия свободный.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Напишим свой нер попробовав разные подходы:\n",
        "  * передаём в сетку токен и его соседей\n",
        "  * передаём в сетку только токен\n",
        "  * свой вариант"
      ],
      "metadata": {
        "id": "zneVFzfARykd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'Collection5/'\n",
        "records = load_ne5(dir)\n",
        "document = next(records).text\n",
        "nltk.pos_tag(nltk.word_tokenize(document))[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiGcRzO-FlO6",
        "outputId": "7fa68fb0-3ee9-47b8-8b73-6ee06e1a0bc6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Мособлдума', 'JJ'),\n",
              " ('позволила', 'NNP'),\n",
              " ('Андрею', 'NNP'),\n",
              " ('Воробьеву', 'NNP'),\n",
              " ('возглавить', 'NNP'),\n",
              " ('правительство', 'NNP'),\n",
              " ('Московская', 'NNP'),\n",
              " ('областная', 'NNP'),\n",
              " ('дума', 'NNP'),\n",
              " ('совместила', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ],
      "metadata": {
        "id": "NaH8Yc5NP6px"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])\n",
        "df_words['tag'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfb4QJfCP82y",
        "outputId": "fc95b19d-f247-42e1-c0f8-425ec03c6be4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         219060\n",
              "PER          21184\n",
              "ORG          13646\n",
              "LOC           4564\n",
              "GEOPOLIT      4355\n",
              "MEDIA         2482\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "metadata": {
        "id": "N543vsjXP-mq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "train_data = train_data.batch(256)\n",
        "valid_data = valid_data.batch(256)"
      ],
      "metadata": {
        "id": "fIV5lJDJQhjq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "gAvwNwdrQkea"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize=None,\n",
        "    max_tokens=30000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=10)\n",
        "\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "Ty_f7HvYQocK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class modelNER(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(modelNER, self).__init__()\n",
        "        self.emb = Embedding(30000, 64)\n",
        "        self.gPool = GlobalMaxPooling1D()\n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.dr1 = Dropout(0.5)\n",
        "        self.fc2 = Dense(100, activation='relu')\n",
        "        self.dr2 = Dropout(0.25)\n",
        "        self.fc3 = Dense(50, activation='relu')\n",
        "        self.fc4 = Dense(6, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        pool_x = self.gPool(x)\n",
        "        \n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.dr1(fc_x)\n",
        "        fc_x = self.fc2(fc_x)\n",
        "        fc_x = self.dr2(fc_x)\n",
        "        fc_x = self.fc3(fc_x)\n",
        "        \n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
        "        prob = self.fc4(concat_x)\n",
        "        return prob"
      ],
      "metadata": {
        "id": "dCqh8ZORS7SR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()\n",
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtmkI1sMS-ZC",
        "outputId": "9f3f91b4-37ff-435f-c882-5e8ba53b1134"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "778/778 [==============================] - 27s 31ms/step - loss: 0.4013 - accuracy: 0.8812 - val_loss: 0.2323 - val_accuracy: 0.9295\n",
            "Epoch 2/3\n",
            "778/778 [==============================] - 24s 31ms/step - loss: 0.1601 - accuracy: 0.9519 - val_loss: 0.2094 - val_accuracy: 0.9398\n",
            "Epoch 3/3\n",
            "778/778 [==============================] - 25s 32ms/step - loss: 0.1219 - accuracy: 0.9619 - val_loss: 0.2358 - val_accuracy: 0.8964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69cd4b2450>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize=None,\n",
        "    max_tokens=30000,\n",
        "    output_mode='int',\n",
        "    ngrams=(1, 3),\n",
        "    output_sequence_length=10)\n",
        "\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "7EGNnWX6TApi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel2 = modelNER()\n",
        "mmodel2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "mmodel2.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L7oBCvYTCBB",
        "outputId": "90462fcb-394c-496a-fd55-f0930ba91111"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "778/778 [==============================] - 27s 35ms/step - loss: 0.3993 - accuracy: 0.8828 - val_loss: 0.2334 - val_accuracy: 0.9294\n",
            "Epoch 2/3\n",
            "778/778 [==============================] - 25s 32ms/step - loss: 0.1576 - accuracy: 0.9525 - val_loss: 0.2069 - val_accuracy: 0.9379\n",
            "Epoch 3/3\n",
            "778/778 [==============================] - 25s 32ms/step - loss: 0.1222 - accuracy: 0.9617 - val_loss: 0.2071 - val_accuracy: 0.9412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69cfa01150>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Сравнить реализованные подходы на качество"
      ],
      "metadata": {
        "id": "1h61udJxR2ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**\n",
        "\n",
        "n-gram показал не самых хороший результат, в отличии от отдельными токенами"
      ],
      "metadata": {
        "id": "-A9DZfCWTQIH"
      }
    }
  ]
}