{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating a feature space.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MYhOMWTRWgty7cH8qj_KjrjoI6s0e9ZD",
      "authorship_tag": "ABX9TyO5HXv8/x/bt8bXr3E1Gmof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteAndBlackFox/nlp/blob/lessons2/Creating_a_feature_space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBlSDhWOcZfF"
      },
      "source": [
        "# Создание признакового пространства"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт библиотек"
      ],
      "metadata": {
        "id": "x9ZCGYSgd6WM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEy6QBH-cbuE",
        "outputId": "cfc8ab62-ba8f-4d67-8fc0-c8d260fa7dfd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import nltk\n",
        "from nltk import collocations\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "for i in ['genesis', 'stopwords', 'punkt']:\n",
        "  nltk.download(i)\n",
        "\n",
        "import pickle\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготавливаем данные"
      ],
      "metadata": {
        "id": "XUbSUVemgM3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title скачиваем данные\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YThGYntoeHAj",
        "outputId": "a7a1f80b-eb0f-4188-fcaf-b50533802b2a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-08 18:42:43--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2022-06-08 18:42:43--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc77821db034bb9f19af04373055.dl.dropboxusercontent.com/cd/0/inline/Bm28QVOTBlQRCNItUbAmc-9-yh_RZJytLZ7q1HbuzoDot2WL1nGxQuxn5XAQRun2OL9Q8Ymr-nGQB3APe0Q4p3KSZ8l7p68w6e-CovM3Xd-v-krmfkK2OZkk_PvMuzqjVxD9QyhKEv_pCnhc11meOp9fJBbfHHJPREQCDMUAWSJWMw/file# [following]\n",
            "--2022-06-08 18:42:43--  https://uc77821db034bb9f19af04373055.dl.dropboxusercontent.com/cd/0/inline/Bm28QVOTBlQRCNItUbAmc-9-yh_RZJytLZ7q1HbuzoDot2WL1nGxQuxn5XAQRun2OL9Q8Ymr-nGQB3APe0Q4p3KSZ8l7p68w6e-CovM3Xd-v-krmfkK2OZkk_PvMuzqjVxD9QyhKEv_pCnhc11meOp9fJBbfHHJPREQCDMUAWSJWMw/file\n",
            "Resolving uc77821db034bb9f19af04373055.dl.dropboxusercontent.com (uc77821db034bb9f19af04373055.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc77821db034bb9f19af04373055.dl.dropboxusercontent.com (uc77821db034bb9f19af04373055.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv.1’\n",
            "\n",
            "positive.csv.1      100%[===================>]  25.02M  13.2MB/s    in 1.9s    \n",
            "\n",
            "2022-06-08 18:42:46 (13.2 MB/s) - ‘positive.csv.1’ saved [26233379/26233379]\n",
            "\n",
            "--2022-06-08 18:42:46--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2022-06-08 18:42:46--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com/cd/0/inline/Bm3onj5cRhXZVS1PstKnFJP2Nmpg8CoWzStfRxhzqe_b_EKJQYgdmf8C4HRqMhNTxNSqzbZSqoWL2lv-ZSU25kzodc2Xhv6gxYuLg-VFd8TmxE2yVIfo0m0xy6DhWP3LquY2at5mqpiNDY0A4rr-jI3-9PIcXA0lCyxLZdTe7byj1A/file# [following]\n",
            "--2022-06-08 18:42:47--  https://uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com/cd/0/inline/Bm3onj5cRhXZVS1PstKnFJP2Nmpg8CoWzStfRxhzqe_b_EKJQYgdmf8C4HRqMhNTxNSqzbZSqoWL2lv-ZSU25kzodc2Xhv6gxYuLg-VFd8TmxE2yVIfo0m0xy6DhWP3LquY2at5mqpiNDY0A4rr-jI3-9PIcXA0lCyxLZdTe7byj1A/file\n",
            "Resolving uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com (uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com)... 162.125.8.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com (uc07a9f5d01996d390463e9bfef2.dl.dropboxusercontent.com)|162.125.8.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv.1’\n",
            "\n",
            "negative.csv.1      100%[===================>]  23.32M  31.9MB/s    in 0.7s    \n",
            "\n",
            "2022-06-08 18:42:48 (31.9 MB/s) - ‘negative.csv.1’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = stopwords.words('russian') + list(punctuation)"
      ],
      "metadata": {
        "id": "ybTFVi7UYaLh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = pd.read_csv('positive.csv', sep=\";\",  usecols=[3], names=['text'])\n",
        "pos['label'] = ['positive'] * len(pos)\n",
        "neg = pd.read_csv('negative.csv', sep=\";\",  usecols=[3], names=['text'])\n",
        "neg['label'] = ['negative'] * len(neg)\n",
        "df = pos.append(neg)\n",
        "watch_df = df.iloc[np.r_[0:5, -5:0]]\n",
        "print(watch_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7b1RMuqgWW8",
        "outputId": "58ee3100-736e-44d0-bc10-580a85eeffb9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     text     label\n",
            "0       @first_timee хоть я и школота, но поверь, у на...  positive\n",
            "1       Да, все-таки он немного похож на него. Но мой ...  positive\n",
            "2       RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
            "3       RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
            "4       @irina_dyshkant Вот что значит страшилка :D\\nН...  positive\n",
            "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
            "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
            "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
            "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
            "111922  Такси везет меня на работу. Раздумываю приплат...  negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ],
      "metadata": {
        "id": "YIBCLKq1iCHs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVU1nYAamcYU",
        "outputId": "22443e33-a564-4531-a11b-2347c43995ba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted = sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaCKax45nK6b",
        "outputId": "73cca1d4-04f5-4537-f65e-60ca46195c3e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 69267),\n",
              " ('и', 54916),\n",
              " ('в', 52853),\n",
              " ('я', 52506),\n",
              " ('RT', 38070),\n",
              " ('на', 35715),\n",
              " ('http', 32992),\n",
              " ('что', 31472),\n",
              " ('...', 28773),\n",
              " ('с', 27176)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1\n",
        "Обучить три классификатора и сравнить полученные результаты, оценить какие токены наиболее важные для классификации :\n",
        "1. на токенах с высокой частотой\n",
        "2. на токенах со средней частотой\n",
        "3. на токенах с низкой частотой\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RYCzwxJ-dIZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_freq = 10000 # по закону Ципфа в основном используют высокие ранги с 10**7 (http://rcdl.ru/doc/2006/paper_72_v1.pdf), но будем использовать поменьше 10**4, т.к. иначе все попадает в среднюю выборку\n",
        "small_freq = 1000 # по закону Ципфа в основном используют низкие ранги с 10**5 (http://rcdl.ru/doc/2006/paper_72_v1.pdf), но будем использовать поменьше 10**3, т.к. иначе все попадает в среднюю выборку\n",
        "\n",
        "high_tokens = []\n",
        "middle_tokens = []\n",
        "little_tokens = []"
      ],
      "metadata": {
        "id": "KENPTbIBd5YL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in freq_dict_sorted:\n",
        "  if i[1] > high_freq:\n",
        "    high_tokens.append(i[0])\n",
        "  elif i[1] < small_freq:\n",
        "    middle_tokens.append(i[0])\n",
        "  else:\n",
        "    little_tokens.append(i[0])\n",
        "print(f\"Количество токенов с высокой частотой: {len(high_tokens)}.\\n\" +\n",
        "      f\"Количество токенов со средней частотой: {len(middle_tokens)}.\\n\" + \n",
        "      f\"Количество токенов с низкой частотой: {len(little_tokens)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VbUwrUsWOth",
        "outputId": "aef36a23-8dc4-4f74-c476-b8bee7d548fa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество токенов с высокой частотой: 28.\n",
            "Количество токенов со средней частотой: 359368.\n",
            "Количество токенов с низкой частотой: 225.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def report_token(baseline, x_train, x_test, y_train, y_test):\n",
        "  %%time\n",
        "  bow = baseline.fit_transform(x_train)\n",
        "  clf = LogisticRegression(random_state=42)\n",
        "  clf.fit(bow, y_train)\n",
        "  pred = clf.predict(baseline.transform(x_test))\n",
        "  print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "id": "pppiiT2EYDQa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Считаем токены с высокой частотой\n",
        "stop_words = noise + middle_tokens + little_tokens\n",
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words)\n",
        "report_token(vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A_84NBgYu8x",
        "outputId": "f6607034-9ec7-479f-b967-ba0863639e0b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 10 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.57      0.67     38651\n",
            "    positive       0.43      0.68      0.53     18058\n",
            "\n",
            "    accuracy                           0.61     56709\n",
            "   macro avg       0.61      0.63      0.60     56709\n",
            "weighted avg       0.68      0.61      0.62     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Считаем токены для средней частоты\n",
        "stop_words = noise + high_tokens + little_tokens\n",
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words)\n",
        "report_token(vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WlsLpilbW9h",
        "outputId": "1aaf0d57-44e1-442c-d287-e462da1a96ae"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.3 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.74      0.77     29973\n",
            "    positive       0.73      0.79      0.76     26736\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Считаем токены для низкой частоты\n",
        "stop_words = noise + high_tokens + middle_tokens\n",
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words)\n",
        "report_token(vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K_OCxbnbeyh",
        "outputId": "afab21f6-6394-4627-8285-d14a1185ee42"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.96 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.45      0.67      0.54     18677\n",
            "    positive       0.78      0.59      0.68     38032\n",
            "\n",
            "    accuracy                           0.62     56709\n",
            "   macro avg       0.62      0.63      0.61     56709\n",
            "weighted avg       0.67      0.62      0.63     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**\n",
        "\n",
        "Судя по границам, которые задали лучшая точность у токенов получилась на средей частоте."
      ],
      "metadata": {
        "id": "3NPDtMcMcOq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2\n",
        "Найти фичи с наибольшей значимостью, и вывести их.\n",
        "\n"
      ],
      "metadata": {
        "id": "nShloZUod1Oc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Немного теории.\n",
        "Т.к. анализируем чат, то явно в чате используются тектовые смайлики и они так же несут смысловую нагрузку на текст, из-за чего точность можно улучшить, если их не будем принимать как стоп-слова. Первое что приходит в голову это улыбающийся смайлик: \n",
        "*   )\n",
        "*   :)\n",
        "Проверим на них."
      ],
      "metadata": {
        "id": "vJS03Nm_ex6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = ['positive' if (')' in tweet or ':)' in tweet) else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0ASeU2dLTx",
        "outputId": "bb6c09e3-1dee-4a83-bd98-b79d58ce6237"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.85      0.92     32821\n",
            "    positive       0.83      1.00      0.91     23888\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.91      0.92      0.91     56709\n",
            "weighted avg       0.93      0.91      0.91     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Довольно таки не плохо, на самом деле. Что же проверим какие вообще фичи с наибольшей значимостью у нас используется в переписке."
      ],
      "metadata": {
        "id": "NRHAbTJ4iAVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fichi_token = dict()\n",
        "for punkt in punctuation:\n",
        "  pred = ['positive' if punkt in tweet else 'negative' for tweet in x_test]\n",
        "  fichi_token[punkt] = accuracy_score(pred, y_test)\n",
        "print(fichi_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws549WmqibZZ",
        "outputId": "37528bf8-43fa-4b36-86be-4bed06436e6a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'!': 0.5117000828792608, '\"': 0.5035884956532473, '#': 0.5020190798638664, '$': 0.4911566065351179, '%': 0.4932903066532649, '&': 0.4915798197816925, \"'\": 0.4912095081909397, '(': 0.02608051632016082, ')': 0.9124830273854239, '*': 0.5096369183022095, '+': 0.4917914264049798, ',': 0.5038177361618086, '-': 0.5093724100231004, '.': 0.5119116895025481, '/': 0.5434058086018092, ':': 0.5468973178860498, ';': 0.4969934225607928, '<': 0.4912447759614876, '=': 0.49159745366696644, '>': 0.4912447759614876, '?': 0.501842741011127, '@': 0.5665767338517695, '[': 0.4912800437320355, '\\\\': 0.4912447759614876, ']': 0.49131531150258334, '^': 0.4974342696926414, '_': 0.518065915463154, '`': 0.49089209825600877, '{': 0.4912800437320355, '|': 0.4867305013313583, '}': 0.4912800437320355, '~': 0.49122714207621365}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ficha in sorted(fichi_token.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "  print(f\"{ficha[0]} - {ficha[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw7YnqgKjTyZ",
        "outputId": "6cd642ff-119c-482a-f71b-88461d463063"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ") - 0.9124830273854239\n",
            "@ - 0.5665767338517695\n",
            ": - 0.5468973178860498\n",
            "/ - 0.5434058086018092\n",
            "_ - 0.518065915463154\n",
            ". - 0.5119116895025481\n",
            "! - 0.5117000828792608\n",
            "* - 0.5096369183022095\n",
            "- - 0.5093724100231004\n",
            ", - 0.5038177361618086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3\n",
        " 1. сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
        " 2. подобрать оптимальный размер для hashing векторайзера\n",
        " 3. убедиться что для сетки нет переобучения"
      ],
      "metadata": {
        "id": "7aglfVBwdKoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('russian') + list(punctuation)\n",
        "\n",
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words)\n",
        "report_token(vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR5aSIhakUIR",
        "outputId": "d297b367-19f8-4383-d033-be968fffdd87"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 5.96 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.76      0.78     29181\n",
            "    positive       0.76      0.80      0.78     27528\n",
            "\n",
            "    accuracy                           0.78     56709\n",
            "   macro avg       0.78      0.78      0.78     56709\n",
            "weighted avg       0.78      0.78      0.78     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('russian')\n",
        "\n",
        "tf_vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words)\n",
        "report_token(tf_vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TzYlhbBm6fj",
        "outputId": "8cc1c68e-75df-431f-a4ba-4b2f9c5cf626"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00     27832\n",
            "    positive       1.00      1.00      1.00     28877\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in [2**4, 2**8, 2**10]:\n",
        "  hash_vec = HashingVectorizer(n_features=param)\n",
        "  print(f\"HashingVectorizer with {param}.\\n\")\n",
        "  report_token(hash_vec, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAjSibADnKYh",
        "outputId": "037e9ee3-6440-45a5-cf7b-ddd3ff70b47b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HashingVectorizer with 16.\n",
            "\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.54      0.52     26167\n",
            "    positive       0.58      0.55      0.56     30542\n",
            "\n",
            "    accuracy                           0.54     56709\n",
            "   macro avg       0.54      0.54      0.54     56709\n",
            "weighted avg       0.54      0.54      0.54     56709\n",
            "\n",
            "HashingVectorizer with 256.\n",
            "\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.68 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.60      0.61      0.60     27404\n",
            "    positive       0.63      0.62      0.62     29305\n",
            "\n",
            "    accuracy                           0.61     56709\n",
            "   macro avg       0.61      0.61      0.61     56709\n",
            "weighted avg       0.61      0.61      0.61     56709\n",
            "\n",
            "HashingVectorizer with 1024.\n",
            "\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.63      0.65      0.64     27206\n",
            "    positive       0.67      0.66      0.66     29503\n",
            "\n",
            "    accuracy                           0.65     56709\n",
            "   macro avg       0.65      0.65      0.65     56709\n",
            "weighted avg       0.65      0.65      0.65     56709\n",
            "\n"
          ]
        }
      ]
    }
  ]
}