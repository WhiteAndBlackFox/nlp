{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Сверточные нейронные сети для анализа текста.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0ZQVR_dVMN9M",
        "XevvBxkrIySW",
        "yo8JJ8K9I251"
      ],
      "authorship_tag": "ABX9TyNg9+p4pwEBscsHott17JFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteAndBlackFox/nlp/blob/ConvolutionalNN/%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%D0%B4%D0%BB%D1%8F_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сверточные нейронные сети для анализа текста"
      ],
      "metadata": {
        "id": "p9ukmzWUIchm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Доставляем и импортируем библиотеки"
      ],
      "metadata": {
        "id": "Zj5V9phsJrHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow pandas xlrd #tensorflow-gpu\n",
        "!pip install keras scikit-learn pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbKUBvqtKAa1",
        "outputId": "21e7bb3c-6a94-4f07-8810-32924ec1235e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Collecting xlrd\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 50.1 MB/s \n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, xlrd, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 xlrd-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 10.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "for val in ['stopwords', 'punkt']:\n",
        "  nltk.download(val)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from keras.losses import categorical_crossentropy, SparseCategoricalCrossentropy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puyvGHoUJvR8",
        "outputId": "c3f3ee21-476d-4fc8-df23-087997875620"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дополнительные функции"
      ],
      "metadata": {
        "id": "4l7GCFxBMG7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"\n",
        "    Функция для предобработки текста\n",
        "  \"\"\"\n",
        "  # Заменим пунктуацию на пробелы.\n",
        "  text = re.sub(\"[^\\w\\s]\", \" \", str(text))\n",
        "  # Заменим спецсимволы на пробелы и числа.\n",
        "  text = re.sub(\"[^a-zA-Zа-яёА-ЯЁ\\_]\", \" \", text)\n",
        "  # Получаем токены\n",
        "  text = word_tokenize(text)\n",
        "  # Удаляем стоп слова\n",
        "  text = [w for w in text if w not in stopwordslist]\n",
        "  # Нормализация текста\n",
        "  text = [morpher.parse(word)[0].normal_form for word in text if word not in stopwordslist]\n",
        "  return \" \".join(text)\n",
        "\n",
        "def text_to_sequence(text, maxlen, vocabulary):\n",
        "  \"\"\"\n",
        "    Функция для получения последовательности\n",
        "  \"\"\"\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "  result = [vocabulary[word] for word in tokens_filtered if word in vocabulary]\n",
        "  padding = [0]*(maxlen-len(result))\n",
        "  return padding + result[-maxlen:]\n",
        "\n",
        "def fit_evalute_model(model, x_train, y_train, x_test, y_test):\n",
        "\n",
        "  model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_split=0.1)\n",
        "  \n",
        "  score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "-WkItyuVMJm8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовим данные"
      ],
      "metadata": {
        "id": "0ZQVR_dVMN9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Глобальные переменные\n",
        "max_words = 20000\n",
        "max_len = 150\n",
        "num_classes = 5\n",
        "embedding_dim = 300\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "print_batch_n = 100\n",
        "\n",
        "stopwordslist = stopwords.words(\"russian\")\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "path_model = \"./model/model.txt\""
      ],
      "metadata": {
        "id": "bW-U2A7qNxwk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O 'отзывы за лето.xls' -qq --no-check-certificate https://gbcdn.mrgcdn.ru/uploads/asset/2800837/attachment/b61f2b2ddfad7d8623540e93cea07b20.xls\n",
        "!wget -O 'model.zip' -qq --no-check-certificate http://vectors.nlpl.eu/repository/20/220.zip\n",
        "!unzip 'model.zip' -d './model/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s81sAZRBaw6J",
        "outputId": "0e78a73b-5eaf-4163-be71-13fc91e69457"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.zip\n",
            "  inflating: ./model/meta.json       \n",
            "  inflating: ./model/model.bin       \n",
            "  inflating: ./model/model.txt       \n",
            "  inflating: ./model/README          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('отзывы за лето.xls')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uiyYnRaWMOgk",
        "outputId": "5e846b04-2c03-4716-a433-85fd5fe974c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Rating                                            Content        Date\n",
              "0       5                                     It just works!  2017-08-14\n",
              "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
              "2       5                                        Отлично все  2017-08-14\n",
              "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
              "4       5                     Очень удобно, работает быстро.  2017-08-14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16dc4223-68fa-456a-85ec-f84c695dd7e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Отлично все</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Очень удобно, работает быстро.</td>\n",
              "      <td>2017-08-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16dc4223-68fa-456a-85ec-f84c695dd7e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16dc4223-68fa-456a-85ec-f84c695dd7e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16dc4223-68fa-456a-85ec-f84c695dd7e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocess'] = df['Content'].progress_apply(lambda x: clean_text(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O4NXHQpRUQr",
        "outputId": "dd2debf1-256c-4d36-81f0-03e0b71a32c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20659/20659 [00:39<00:00, 519.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Учим conv сеть для классификации"
      ],
      "metadata": {
        "id": "XevvBxkrIySW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(df['preprocess'])\n",
        "train_tokens = word_tokenize(train_corpus)\n",
        "train_tokens_filtered = [word for word in train_tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "fOhZJLbJSoy6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = FreqDist(train_tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkqjFBkLStXS",
        "outputId": "ddf77a26-b6fb-421e-ad27-959013fbe7b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['приложение',\n",
              " 'очень',\n",
              " 'удобно',\n",
              " 'всё',\n",
              " 'работать',\n",
              " 'удобный',\n",
              " 'спасибо',\n",
              " 'отлично',\n",
              " 'нравиться',\n",
              " 'я']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "metadata": {
        "id": "je-RJ2eASwXa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_seq = np.asarray([text_to_sequence(text, max_len, vocabulary) for text in df['preprocess']], dtype=np.int32)"
      ],
      "metadata": {
        "id": "fE8J3rTVTTSE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df_train_seq, df['Rating'], test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "cwRz3as5UT9K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train) \n",
        "y_test = le.transform(y_test)\n",
        "le.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE63St9eU2bx",
        "outputId": "ba4e7121-f806-40a9-eba4-7a85d2ccc630"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Рассмотрим два варианта сеточек\n"
      ],
      "metadata": {
        "id": "FNMV1-c7I0kW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Инициализировав tf.keras.layers.Embedding предобученными векторами взятых из https://rusvectores.org/ru/\n"
      ],
      "metadata": {
        "id": "yo8JJ8K9I251"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(path_model) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OFdsO4TU7JC",
        "outputId": "fb15ed2b-5cb0-4dff-8101-29e86d70b4f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 249334 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word in tokens_filtered_top:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[tokens_filtered_top.index(word)] = embedding_vector"
      ],
      "metadata": {
        "id": "JcpHApblhiEW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        " Embedding(input_dim=max_words, weights=[embedding_matrix], output_dim=embedding_dim, input_length=max_len),\n",
        " Conv1D(128, 3, activation=\"relu\"),\n",
        " GlobalMaxPool1D(),\n",
        " Dense(10, activation=\"relu\"),\n",
        " Dense(num_classes, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "w7s8NtgGhrYd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_evalute_model(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SprWR40_h90N",
        "outputId": "4528eca0-0169-4cd3-ea04-d824cb691f3d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.5978 - accuracy: 0.6775 - val_loss: 1.5847 - val_accuracy: 0.7011\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 40s 2s/step - loss: 1.5733 - accuracy: 0.7030 - val_loss: 1.5605 - val_accuracy: 0.7011\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.5492 - accuracy: 0.7030 - val_loss: 1.5370 - val_accuracy: 0.7011\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.5258 - accuracy: 0.7030 - val_loss: 1.5139 - val_accuracy: 0.7011\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 37s 1s/step - loss: 1.5030 - accuracy: 0.7030 - val_loss: 1.4916 - val_accuracy: 0.7011\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 36s 1s/step - loss: 1.4808 - accuracy: 0.7030 - val_loss: 1.4700 - val_accuracy: 0.7011\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 37s 1s/step - loss: 1.4593 - accuracy: 0.7030 - val_loss: 1.4488 - val_accuracy: 0.7011\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.4384 - accuracy: 0.7030 - val_loss: 1.4283 - val_accuracy: 0.7011\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.4182 - accuracy: 0.7030 - val_loss: 1.4086 - val_accuracy: 0.7011\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.3986 - accuracy: 0.7030 - val_loss: 1.3894 - val_accuracy: 0.7011\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.3796 - accuracy: 0.7030 - val_loss: 1.3710 - val_accuracy: 0.7011\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.3614 - accuracy: 0.7030 - val_loss: 1.3531 - val_accuracy: 0.7011\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.3438 - accuracy: 0.7030 - val_loss: 1.3359 - val_accuracy: 0.7011\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 37s 1s/step - loss: 1.3267 - accuracy: 0.7030 - val_loss: 1.3192 - val_accuracy: 0.7011\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 37s 1s/step - loss: 1.3103 - accuracy: 0.7030 - val_loss: 1.3034 - val_accuracy: 0.7011\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.2946 - accuracy: 0.7030 - val_loss: 1.2881 - val_accuracy: 0.7011\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.2795 - accuracy: 0.7030 - val_loss: 1.2733 - val_accuracy: 0.7011\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.2649 - accuracy: 0.7030 - val_loss: 1.2593 - val_accuracy: 0.7011\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.2510 - accuracy: 0.7030 - val_loss: 1.2457 - val_accuracy: 0.7011\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 40s 2s/step - loss: 1.2376 - accuracy: 0.7030 - val_loss: 1.2328 - val_accuracy: 0.7011\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 1.2223 - accuracy: 0.7125\n",
            "Test score: 1.2222684621810913\n",
            "Test accuracy: 0.7125256657600403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Инициализировав слой tf.keras.layers.Embedding по умолчанию"
      ],
      "metadata": {
        "id": "5y0NgjScI5_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        " Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
        " Conv1D(128, 3, activation=\"relu\"),\n",
        " GlobalMaxPool1D(),\n",
        " Dense(10, activation=\"relu\"),\n",
        " Dense(num_classes, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "5S3JTjIHU7dJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_evalute_model(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lUM6U_QWWzJ",
        "outputId": "85f3bb9d-abfe-4cec-ea2f-b83a2842a9ea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 16s 624ms/step - loss: 0.3868 - accuracy: 0.8674 - val_loss: 0.8772 - val_accuracy: 0.7473\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 16s 625ms/step - loss: 0.3606 - accuracy: 0.8723 - val_loss: 0.9039 - val_accuracy: 0.7458\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 17s 662ms/step - loss: 0.3422 - accuracy: 0.8737 - val_loss: 0.9302 - val_accuracy: 0.7394\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 17s 673ms/step - loss: 0.3244 - accuracy: 0.8801 - val_loss: 0.9777 - val_accuracy: 0.7394\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.3067 - accuracy: 0.8926 - val_loss: 1.0062 - val_accuracy: 0.7350\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.2914 - accuracy: 0.9003 - val_loss: 1.0611 - val_accuracy: 0.7350\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.2757 - accuracy: 0.9072 - val_loss: 1.1143 - val_accuracy: 0.7350\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 16s 625ms/step - loss: 0.2580 - accuracy: 0.9144 - val_loss: 1.1376 - val_accuracy: 0.7379\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 16s 633ms/step - loss: 0.2444 - accuracy: 0.9229 - val_loss: 1.2105 - val_accuracy: 0.7357\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 17s 684ms/step - loss: 0.2293 - accuracy: 0.9356 - val_loss: 1.2633 - val_accuracy: 0.7343\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 16s 645ms/step - loss: 0.2162 - accuracy: 0.9382 - val_loss: 1.3129 - val_accuracy: 0.7278\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.2049 - accuracy: 0.9446 - val_loss: 1.3763 - val_accuracy: 0.7300\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 16s 636ms/step - loss: 0.1945 - accuracy: 0.9475 - val_loss: 1.4535 - val_accuracy: 0.7264\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 20s 792ms/step - loss: 0.1858 - accuracy: 0.9505 - val_loss: 1.5118 - val_accuracy: 0.7314\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.1762 - accuracy: 0.9529 - val_loss: 1.5568 - val_accuracy: 0.7285\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 16s 627ms/step - loss: 0.1701 - accuracy: 0.9538 - val_loss: 1.6334 - val_accuracy: 0.7235\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.1676 - accuracy: 0.9546 - val_loss: 1.6643 - val_accuracy: 0.7264\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.1581 - accuracy: 0.9570 - val_loss: 1.7383 - val_accuracy: 0.7314\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.1519 - accuracy: 0.9587 - val_loss: 1.7870 - val_accuracy: 0.7350\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 16s 632ms/step - loss: 0.1467 - accuracy: 0.9592 - val_loss: 1.8302 - val_accuracy: 0.7314\n",
            "14/14 [==============================] - 2s 154ms/step - loss: 1.7674 - accuracy: 0.7329\n",
            "Test score: 1.767443299293518\n",
            "Test accuracy: 0.7329128980636597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
      ],
      "metadata": {
        "id": "j0zmMo4_I9ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**:\n",
        "\n",
        "В качестве предобученных весов использовалась сборка под индентификатором \"ruwikiruscorpora_upos_cbow_300_10_2021\". По результатам сетка, где использовался словарь именно из текста отработал лучше (*score*: 1.767443299293518, *accuracy*: 0.7329128980636597), чем сетка собранная из весов стороннего текста (*score*: 1.2222684621810913, *accuracy*: 0.7125256657600403)."
      ],
      "metadata": {
        "id": "7eDlOu8vkejU"
      }
    }
  ]
}